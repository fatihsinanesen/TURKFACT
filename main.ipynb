{"cells":[{"cell_type":"markdown","source":["### **Libraries:**"],"metadata":{"id":"pg3w27aN9NMP"}},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1XKz7N9CLoI","outputId":"3040ecea-1925-4152-e5ff-089246293e34","executionInfo":{"status":"ok","timestamp":1718208216393,"user_tz":-180,"elapsed":36150,"user":{"displayName":"Fatih Sinan Esen","userId":"08302724942116971542"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: plot-metric in /usr/local/lib/python3.10/dist-packages (0.0.6)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from plot-metric) (1.11.4)\n","Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from plot-metric) (3.7.1)\n","Requirement already satisfied: colorlover>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from plot-metric) (0.3.0)\n","Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from plot-metric) (2.0.3)\n","Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from plot-metric) (0.13.1)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from plot-metric) (1.25.2)\n","Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from plot-metric) (1.2.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot-metric) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot-metric) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot-metric) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot-metric) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot-metric) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot-metric) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot-metric) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot-metric) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->plot-metric) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->plot-metric) (2024.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->plot-metric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->plot-metric) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.2->plot-metric) (1.16.0)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n","Requirement already satisfied: TurkishStemmer in /usr/local/lib/python3.10/dist-packages (1.3)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n","Requirement already satisfied: xlwt in /usr/local/lib/python3.10/dist-packages (1.3.0)\n","Requirement already satisfied: sklearn-genetic-opt in /usr/local/lib/python3.10/dist-packages (0.10.1)\n","Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-genetic-opt) (1.2.2)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-genetic-opt) (1.25.2)\n","Requirement already satisfied: deap>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-genetic-opt) (1.4.1)\n","Requirement already satisfied: tqdm>=4.61.1 in /usr/local/lib/python3.10/dist-packages (from sklearn-genetic-opt) (4.66.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->sklearn-genetic-opt) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->sklearn-genetic-opt) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->sklearn-genetic-opt) (3.5.0)\n","Requirement already satisfied: sklearn-genetic-opt[all] in /usr/local/lib/python3.10/dist-packages (0.10.1)\n","Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-genetic-opt[all]) (1.2.2)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-genetic-opt[all]) (1.25.2)\n","Requirement already satisfied: deap>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-genetic-opt[all]) (1.4.1)\n","Requirement already satisfied: tqdm>=4.61.1 in /usr/local/lib/python3.10/dist-packages (from sklearn-genetic-opt[all]) (4.66.4)\n","Requirement already satisfied: mlflow>=1.30.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-genetic-opt[all]) (2.13.2)\n","Requirement already satisfied: seaborn>=0.11.2 in /usr/local/lib/python3.10/dist-packages (from sklearn-genetic-opt[all]) (0.13.1)\n","Requirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-genetic-opt[all]) (2.15.0)\n","Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (2.2.5)\n","Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (1.13.1)\n","Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (5.3.3)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (8.1.7)\n","Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (2.2.1)\n","Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (7.1.0)\n","Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (0.4)\n","Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (3.1.43)\n","Requirement already satisfied: graphene<4 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (3.3)\n","Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (7.1.0)\n","Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (3.6)\n","Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (3.7.1)\n","Requirement already satisfied: opentelemetry-api<3,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (1.25.0)\n","Requirement already satisfied: opentelemetry-sdk<3,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (1.25.0)\n","Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (24.0)\n","Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (2.0.3)\n","Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (3.20.3)\n","Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (14.0.2)\n","Requirement already satisfied: pytz<2025 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (2023.4)\n","Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (6.0.1)\n","Requirement already satisfied: querystring-parser<2 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (1.2.4)\n","Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (2.31.0)\n","Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (1.11.4)\n","Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (2.0.30)\n","Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (0.5.0)\n","Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (3.1.4)\n","Requirement already satisfied: gunicorn<23 in /usr/local/lib/python3.10/dist-packages (from mlflow>=1.30.0->sklearn-genetic-opt[all]) (22.0.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->sklearn-genetic-opt[all]) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->sklearn-genetic-opt[all]) (3.5.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (4.12.1)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (1.64.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->sklearn-genetic-opt[all]) (2.15.0)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow>=1.30.0->sklearn-genetic-opt[all]) (1.3.5)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->sklearn-genetic-opt[all]) (0.43.0)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow>=1.30.0->sklearn-genetic-opt[all]) (2.0.7)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow>=1.30.0->sklearn-genetic-opt[all]) (3.0.3)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow>=1.30.0->sklearn-genetic-opt[all]) (2.2.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow>=1.30.0->sklearn-genetic-opt[all]) (4.0.11)\n","Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow>=1.30.0->sklearn-genetic-opt[all]) (3.2.3)\n","Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow>=1.30.0->sklearn-genetic-opt[all]) (3.2.0)\n","Requirement already satisfied: aniso8601<10,>=8 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow>=1.30.0->sklearn-genetic-opt[all]) (9.0.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow>=1.30.0->sklearn-genetic-opt[all]) (3.19.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow>=1.30.0->sklearn-genetic-opt[all]) (2.1.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=1.30.0->sklearn-genetic-opt[all]) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=1.30.0->sklearn-genetic-opt[all]) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=1.30.0->sklearn-genetic-opt[all]) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=1.30.0->sklearn-genetic-opt[all]) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=1.30.0->sklearn-genetic-opt[all]) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=1.30.0->sklearn-genetic-opt[all]) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow>=1.30.0->sklearn-genetic-opt[all]) (2.8.2)\n","Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.0.0->mlflow>=1.30.0->sklearn-genetic-opt[all]) (1.2.14)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.0.0->mlflow>=1.30.0->sklearn-genetic-opt[all]) (0.46b0)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow>=1.30.0->sklearn-genetic-opt[all]) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow>=1.30.0->sklearn-genetic-opt[all]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow>=1.30.0->sklearn-genetic-opt[all]) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow>=1.30.0->sklearn-genetic-opt[all]) (2024.6.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow>=1.30.0->sklearn-genetic-opt[all]) (3.0.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.0.0->sklearn-genetic-opt[all]) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.0.0->sklearn-genetic-opt[all]) (1.2.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.0.0->sklearn-genetic-opt[all]) (0.7.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow>=1.30.0->sklearn-genetic-opt[all]) (5.0.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.0.0->sklearn-genetic-opt[all]) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.0.0->sklearn-genetic-opt[all]) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.0.0->sklearn-genetic-opt[all]) (1.3.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.0.0->sklearn-genetic-opt[all]) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.0.0->sklearn-genetic-opt[all]) (3.2.2)\n"]}],"source":["!pip install plot-metric\n","!pip install xgboost\n","!pip install TurkishStemmer\n","!pip install nltk\n","!pip install xlwt\n","!pip install sklearn-genetic-opt\n","!pip install sklearn-genetic-opt[all]\n","\n","from sklearn import metrics, tree, svm, preprocessing\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score\n","from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, RandomizedSearchCV\n","from sklearn.feature_extraction.text import CountVectorizer\n","from nltk.corpus import stopwords\n","from TurkishStemmer import TurkishStemmer\n","from IPython.display import display, HTML\n","from sklearn_genetic import GASearchCV, ExponentialAdapter\n","from sklearn_genetic.space import Continuous, Categorical, Integer\n","from sklearn_genetic.plots import plot_fitness_evolution\n","import pandas as pd\n","import numpy as np\n","import os\n","import re\n","import nltk\n","import pickle\n","import openpyxl\n","import statistics\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from datetime import datetime\n","from pytz import timezone\n","from scipy.stats import uniform as sp_randFloat\n","from scipy.stats import randint as sp_randInt\n","import seaborn as sns\n","\n","folder = ''"]},{"cell_type":"markdown","source":["### **Functions:**"],"metadata":{"id":"p-iwZ-Cy9e33"}},{"cell_type":"code","execution_count":34,"metadata":{"id":"5iGl7cmyy7QF","executionInfo":{"status":"ok","timestamp":1718209236191,"user_tz":-180,"elapsed":491,"user":{"displayName":"Fatih Sinan Esen","userId":"08302724942116971542"}}},"outputs":[],"source":["veriseti=\"haberler\"\n","\n","#En çok hangi kelimelerden ötürü ilgili kategoriye karar verdiğini gösterir\n","def most_informative_feature_for_class(vectorizer, classifier, classlabel, n=10):\n","    labelid = list(classifier.classes_).index(classlabel)\n","    feature_names = vectorizer.get_feature_names_out()\n","    topn = sorted(zip(classifier.coef_[labelid], feature_names))[-n:]\n","\n","    for coef, feat in topn:\n","        print(classlabel, feat, coef)\n","\n","#Veri için önhazırlık aşaması\n","def prepare_data(data,text_column=0, add_two_grams=False):\n","    nltk.download('stopwords')\n","    stemmer = TurkishStemmer()\n","\n","    corpus = []\n","    i = 0\n","    for i in range(0, len(data)):\n","        try:\n","            x = data.iloc[i][text_column]\n","            sentence = re.sub(\"\\W+\", \" \", x)\n","            sentence = sentence.replace(\"İ\",\"i\")\n","            sentence = sentence.replace(\"I\",\"ı\")\n","            sentence = sentence.lower()\n","            word_list = sentence.split()\n","            stemmed_word_list = []\n","\n","            prevWord = \"\" #two_grams için\n","\n","            for word in word_list:\n","                if not word in stopwords.words('turkish'):\n","                    if word.isalpha():\n","                        try:\n","                          stemmed_word_list.append(stemmer.stem(word))\n","\n","                          if add_two_grams:\n","                            phrase = prevWord + word\n","                            stemmed_word_list.append(stemmer.stem(phrase))\n","                            prevWord = word\n","\n","                        except Exception as ex2:\n","                          pass\n","\n","            new_sentence = re.sub(\"\\W+\",\" \",re.sub(r'\\b[a-zA-Z]{1}\\b', \" \", re.sub(\"\\d\", \"\", \" \".join(stemmed_word_list))))\n","            corpus.append(new_sentence)\n","        except Exception  as ex:\n","            x = data.iloc[i][text_column]\n","            corpus.append(\" \")\n","            print(\"err docid:\"+str(i)+\":\"+str(x)+\"---\")\n","            print(ex)\n","    return(corpus)\n","\n","#Verilen verisetiyle ve input dosyasıyla ister model_adi'ndan dosya çağırarak, ister model'in ve CountVectorizer'ın kendisini kullanarak sonuç raporu oluştur\n","def sonuc_hazirla(veriseti, test_dosyasi_adi, model_adi=\"\", model=None):\n","  input_data = pd.read_excel(test_dosyasi_adi)\n","  cv = pickle.load(open(\"ai_vectorizer_\" + veriseti + \".pkl\", 'rb'))\n","\n","  if model is None:\n","    model = pickle.load(open(\"ai_model_\" + veriseti + \"_\" + model_adi + \".pkl\", 'rb'))\n","\n","  input_data_corpus = prepare_data(input_data, add_two_grams=False)\n","  cv_test = CountVectorizer(max_features=10000,vocabulary=cv.get_feature_names_out())\n","  X_test_gercek = cv_test.fit_transform(input_data_corpus)\n","\n","  if model_adi == \"XGBClassifier\":\n","    label_encoder = pickle.load(open(\"ai_labelencoder_\" + veriseti + \"_XGBClassifier.pkl\", 'rb'))\n","    predictions = model.predict(X_test_gercek)\n","    predictions_decoded = label_encoder.inverse_transform(predictions)\n","    predictions_df = pd.DataFrame(predictions_decoded, columns=['Predictions'])\n","  else:\n","    predictions = model.predict(X_test_gercek)\n","    predictions_df = pd.DataFrame(predictions, columns=['Predictions'])\n","\n","  rapor = pd.concat([input_data, predictions_df], axis=1)\n","\n","  return(rapor)\n","\n","#Corpus oluşturur, modeli çalıştırır, cross validation yapar, hiperparametre araması yapar\n","def model_build(veriseti, model, altveriseti='data', prepare_corpus=False, add_two_grams=False, build_model=True, make_crossval=False, folds_for_cv=5, make_genetic_opt=False, make_gridsearch_opt=False, make_randomized_opt=False, param_grid=None):\n","  model_adi = model.__class__.__name__\n","  training_data = pd.read_excel(folder + \"/training_data_\" + veriseti + \".xlsx\", sheet_name=altveriseti)\n","  training_data.columns = ['baslik', 'etiket']\n","  sinif_sayisi = training_data.etiket.unique().size #Binary mi multi-class mı?\n","  satir_sayisi = training_data.baslik.size\n","\n","  print(\"---------------- \" + veriseti + \" - \" + altveriseti + \" - \" + model_adi + \" - satır sayısı:\" + str(satir_sayisi) + \" ----------------\")\n","  start_time = datetime.now(timezone('Europe/Istanbul'))\n","  print(\"Start Time = \" + start_time.strftime(\"%H:%M:%S\"))\n","\n","  data_corpus = None\n","\n","  if prepare_corpus: #data_corpus'un hazırlanması istenmiş mi?\n","    data_corpus = prepare_data(training_data, add_two_grams=add_two_grams) #data_corpus'u hazırla\n","    pickle.dump(data_corpus, open(folder + \"/data_corpus_\" + veriseti + \".pkl\",\"wb\")) #data_corpusu kaydet\n","  else:\n","    data_corpus = pickle.load(open(folder + \"/data_corpus_\" + veriseti + \".pkl\", 'rb')) #data_corpus'u dosyadan çağır\n","\n","  if build_model: #modelin eğitilmesi istenmiş mi?\n","    cv = CountVectorizer(max_features=10000)\n","    X = cv.fit_transform(data_corpus).toarray()\n","    pickle.dump(cv, open(folder + \"/ai_vectorizer_\" + veriseti + \".pkl\",\"wb\")) #CountVectorizer'ı pickle'a kaydet (sadece cv.get_feature_names_out()'u çağırmak için gerekli)\n","\n","    y = training_data.etiket\n","\n","    if model_adi == \"XGBClassifier\":\n","      # XGBClassifier'da y sütunu sayısal değer olarak kabul edildiğinden encode etmek icap ediyor\n","      label_encoder = preprocessing.LabelEncoder().fit(y)\n","      pickle.dump(label_encoder, open(folder + \"/ai_labelencoder_\" + veriseti + \"_\" + model_adi + \".pkl\",\"wb\")) #LabelEncoder'ı pickle'a kaydet. XGBClassifier kullanılırsa çağırmak gerekecek.\n","      y = label_encoder.transform(y)\n","\n","    if make_genetic_opt: #Genetik algoritma kullanarak optimal parametreleri bul\n","      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30, stratify=y)\n","      skf = StratifiedKFold(n_splits=folds_for_cv, shuffle=True)\n","      evolved_estimator = GASearchCV(estimator=model, cv=skf, scoring='accuracy', population_size=6, generations=8, param_grid=param_grid, n_jobs=-1, verbose=True)\n","      evolved_estimator.fit(X_train, y_train)\n","      y_predict = evolved_estimator.predict(X_test)\n","      acc = accuracy_score(y_test, y_predict)\n","\n","      print(\"Best accuracy through Genetic Opt: \", acc)\n","      print(\"Best parameters: \", evolved_estimator.best_params_)\n","\n","      pickle.dump(evolved_estimator.estimator, open(folder + \"/ai_model_\" + veriseti + \"_\" + model_adi + \"_geneticOpt.pkl\", \"wb\")) #Optimize edilen modeli pickle'a kaydet\n","\n","      model = evolved_estimator\n","    elif make_gridsearch_opt: #GridSearchCV kullanarak optimal parametreleri bul\n","      skf = StratifiedKFold(n_splits=folds_for_cv)\n","      gridsearched_estimator = GridSearchCV(model, param_grid, n_jobs=-1, cv=skf, verbose=2).fit(X, y)\n","\n","      print('Best accuracy through GridSearch : {:.3f}'.format(gridsearched_estimator.best_score_))\n","      print('Best parameters : {}\\n'.format(gridsearched_estimator.best_params_))\n","\n","      pickle.dump(gridsearched_estimator.estimator, open(folder + \"/ai_model_\" + veriseti + \"_\" + model_adi + \"_gridsearchOpt.pkl\", \"wb\")) #Optimize edilen modeli pickle'a kaydet\n","\n","      model = gridsearched_estimator\n","    elif make_randomized_opt: #RandomizedSearchCV kullanarak optimal parametreleri bul\n","      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30, stratify=y)\n","      skf = StratifiedKFold(n_splits=folds_for_cv)\n","      randomized_estimator = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=skf, n_iter=3, n_jobs=-1, verbose=3)\n","      randomized_estimator.fit(X_train, y_train)\n","      y_predict = randomized_estimator.predict(X_test)\n","      accuracy = accuracy_score(y_test, y_predict)\n","\n","      print(\"The best parameters are: \", randomized_estimator.best_params_)\n","      print(\"The best score: \", randomized_estimator.best_score_)\n","      print(f\"The test accuracy using best parameters: {accuracy:.2f}\")\n","\n","      pickle.dump(randomized_estimator.estimator, open(folder + \"/ai_model_\" + veriseti + \"_\" + model_adi + \"_randomizedsearchOpt.pkl\", \"wb\")) #Optimize edilen modeli pickle'a kaydet\n","      model = randomized_estimator\n","    else: #Sadece tekil bir model eğit\n","      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 20, stratify=y)\n","      model.fit(X_train, y_train)\n","      pickle.dump(model, open(folder + \"/ai_model_\" + veriseti + \"_\" + model_adi + \".pkl\", \"wb\")) #Modeli pickle'a kaydet\n","\n","      y_pred = model.predict(X_test)\n","      y_pred_train = model.predict(X_train)\n","\n","      train_accuracy = accuracy_score(y_train, y_pred_train)\n","      test_accuracy = accuracy_score(y_test, y_pred)\n","      precision = precision_score(y_test, y_pred, average='weighted')\n","      recall = recall_score(y_test, y_pred, average='weighted')\n","      f1score = f1_score(y_test, y_pred, average='weighted')\n","\n","      probs = model.predict_proba(X_test)\n","\n","      roc_auc = 0\n","      if sinif_sayisi == 2:\n","        roc_auc = roc_auc_score(y_test, probs[:,1], average = 'weighted') #Binary classification ise probs 2d array geliyor\n","      else:\n","        roc_auc = roc_auc_score(y_test, probs, multi_class='ovo', average = 'weighted') #Multi-class classification ise probs 1d array geliyor\n","\n","      #print(classification_report(y_test,y_pred)) #sınıf sınıf çok fazla gereksiz bilgi seli\n","      print(\"Train Accuracy = %0.3f\" % train_accuracy)\n","      print(\"Test Accuracy = %0.3f\" % test_accuracy)\n","      print(\"Precision = %0.3f\" % precision)\n","      print(\"Recall = %0.3f\" % recall)\n","      print(\"F1 Score = %0.3f\" % f1score)\n","      print(\"Roc_auc Score = %0.3f\" % roc_auc)\n","\n","      if make_crossval: #Cross validation yap (folds_for_cv: Kaç parçaya bölüneceğini belirtir)\n","        skf = StratifiedKFold(n_splits=folds_for_cv)\n","        scores = cross_val_score(model, X, y, cv=skf)\n","        print(folds_for_cv, \"-fold Stratified Cross Validation sonucu Accuracy ve Standart Sapma: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n","\n","      cf_matrix = confusion_matrix(y_test, y_pred)\n","      categories = training_data.etiket.unique()\n","      make_confusion_matrix(cf_matrix, model_adi, veriseti, categories=categories, accuracy = test_accuracy)\n","\n","  end_time = datetime.now(timezone('Europe/Istanbul'))\n","  delta = end_time - start_time\n","  sec = delta.total_seconds()\n","  min = sec / 60\n","\n","  print(\"End Time = \" + end_time.strftime(\"%H:%M:%S\"))\n","  print(\"Running Time in Minutes: {:.3f}\".format(min))\n","  print(\"----------------------------------------------------------------\")\n","\n","  return model\n","\n","#Detaylı bilgi için: https://github.com/DTrimarchi10/confusion_matrix/blob/master/cf_matrix.py\n","def make_confusion_matrix(cf,\n","                          model_name,\n","                          veriseti,\n","                          group_names=None,\n","                          categories='auto',\n","                          count=True,\n","                          percent=True,\n","                          cbar=True,\n","                          xyticks=True,\n","                          xyplotlabels=True,\n","                          sum_stats=True,\n","                          figsize=None,\n","                          cmap='Blues',\n","                          accuracy=-1):\n","\n","    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n","    blanks = ['' for i in range(cf.size)]\n","\n","    if group_names and len(group_names)==cf.size:\n","        group_labels = [\"{}\\n\".format(value) for value in group_names]\n","    else:\n","        group_labels = blanks\n","\n","    if count:\n","        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n","    else:\n","        group_counts = blanks\n","\n","    if percent:\n","        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n","    else:\n","        group_percentages = blanks\n","\n","    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n","    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n","\n","    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n","    if sum_stats:\n","        #Accuracy is sum of diagonal divided by total observations\n","\n","        if accuracy == -1:\n","          accuracy  = np.trace(cf) / float(np.sum(cf))\n","\n","        #if it is a binary confusion matrix, show some more stats\n","        if len(cf)==2:\n","            #Metrics for Binary Confusion Matrices\n","            precision = cf[1,1] / sum(cf[:,1])\n","            recall    = cf[1,1] / sum(cf[1,:])\n","            f1_score  = 2*precision*recall / (precision + recall)\n","            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n","                accuracy,precision,recall,f1_score)\n","        else:\n","            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n","    else:\n","        stats_text = \"\"\n","\n","    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n","    if figsize==None:\n","        #Get default figure size if not set\n","        figsize = plt.rcParams.get('figure.figsize')\n","\n","    if xyticks==False:\n","        #Do not show categories if xyticks is False\n","        categories=False\n","\n","    # MAKE THE HEATMAP VISUALIZATION\n","    plt.figure(figsize=figsize)\n","    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n","\n","    if xyplotlabels:\n","        plt.ylabel('Doğru Etiketler')\n","        plt.xlabel('Tahmin Edilen Etiketler' + stats_text)\n","    else:\n","        plt.xlabel(stats_text)\n","\n","    plt.title(\"\".join([model_name, \" - \", veriseti]))\n","\n","#Bir veriseti için tüm sınıflandırma algoritmalarını çalıştırır\n","def train_all_models(veriseti, altveriseti='data', prepare_corpus=False, make_crossval=False, folds_for_cv=5):\n","  classifier_collection = {}\n","\n","  print(\"AKTİF VERİSETİ: \" + veriseti + \"-\" + altveriseti)\n","\n","  classifier_collection['MultinomialNB'] = model_build(veriseti, MultinomialNB(), altveriseti=altveriseti, prepare_corpus=prepare_corpus, make_crossval=make_crossval, folds_for_cv=folds_for_cv)\n","  classifier_collection['GaussianNB'] = model_build(veriseti, GaussianNB(), altveriseti=altveriseti, make_crossval=make_crossval, folds_for_cv=folds_for_cv)\n","  classifier_collection['BernoulliNB'] = model_build(veriseti, BernoulliNB(), altveriseti=altveriseti, make_crossval=make_crossval, folds_for_cv=folds_for_cv)\n","  classifier_collection['KNeighborsClassifier'] = model_build(veriseti, KNeighborsClassifier(), altveriseti=altveriseti, make_crossval=make_crossval, folds_for_cv=folds_for_cv)\n","  classifier_collection['LogisticRegression'] = model_build(veriseti, LogisticRegression(random_state=0, class_weight='balanced'), altveriseti=altveriseti, make_crossval=make_crossval, folds_for_cv=folds_for_cv)\n","  classifier_collection['DecisionTreeClassifier'] = model_build(veriseti, tree.DecisionTreeClassifier(), altveriseti=altveriseti, make_crossval=make_crossval, folds_for_cv=folds_for_cv)\n","  classifier_collection['RandomForestClassifier'] = model_build(veriseti, RandomForestClassifier(), altveriseti=altveriseti, make_crossval=make_crossval, folds_for_cv=folds_for_cv)\n","  #classifier_collection['SVC'] = model_build(veriseti, svm.SVC(kernel='sigmoid', decision_function_shape = 'ovo', probability=True), altveriseti=altveriseti, make_crossval=make_crossval, folds_for_cv=folds_for_cv)   #SVC hem gereksiz uzun sürüyor hem de genellikle accuracy score'u kötü\n","  classifier_collection['XGBClassifier'] = model_build(veriseti, XGBClassifier(tree_method='gpu_hist'), altveriseti=altveriseti, make_crossval=make_crossval, folds_for_cv=folds_for_cv)\n","\n","  return classifier_collection"]},{"cell_type":"markdown","source":["### **Model Training and Hyperparameter Tuning:**"],"metadata":{"id":"eTc2zH5hsOhm"}},{"cell_type":"code","source":["#Tüm modelleri train et\n","train_all_models(veriseti, altveriseti='data', prepare_corpus=False)\n","print(\"----\")"],"metadata":{"id":"l2rTJq6bhOjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#XGBClassifier için Hyperparameter Tuning\n","\n","#RandomizedSearch Opt.\n","params_for_random = {'tree_method' :['gpu_hist'], 'min_child_weight': sp_randInt(1, 40), 'gamma': sp_randFloat(0.1, 10), 'subsample': sp_randFloat(0.1, 1), 'colsample_bytree': sp_randFloat(0.1, 1), 'max_depth': sp_randInt(2, 20)}\n","random_model = model_build(veriseti, XGBClassifier(tree_method='gpu_hist'), altveriseti='data', make_randomized_opt=True, folds_for_cv=3, param_grid=params_for_random)\n","print(\"RandomizedSearchCV ile bulunan optimum hiperparametrelerle cross validation: \")\n","the_model=model_build(veriseti, XGBClassifier(**random_model.best_params_), altveriseti='data', make_crossval=True, folds_for_cv=5)\n","\n","#Genetik Opt.\n","params_for_genetic = {'tree_method': Categorical(['gpu_hist']), 'min_child_weight': Integer(1, 40), 'gamma': Continuous(0.1, 10, distribution='log-uniform'), 'subsample': Continuous(0.1, 1, distribution='log-uniform'), 'colsample_bytree': Continuous(0.1, 1, distribution='log-uniform'), 'max_depth': Integer(2, 20)}\n","genetic_model = model_build(veriseti, XGBClassifier(tree_method='gpu_hist'), altveriseti='data', make_genetic_opt=True, folds_for_cv=5, param_grid=params_for_genetic)\n","print(\"GASearchCV ile bulunan optimum hiperparametrelerle cross validation: \")\n","the_model=model_build(veriseti, XGBClassifier(**genetic_model.best_params_), altveriseti='data', make_crossval=True, folds_for_cv=5)\n","\n","#GridSearch Opt.\n","params_for_grid = {'tree_method' :['gpu_hist'], 'min_child_weight': [1, 5, 10, 40], 'gamma': [0.5, 1, 1.5, 2, 5, 10], 'subsample': [0.1, 0.5, 1.0], 'colsample_bytree': [0.1, 0.5, 1.0], 'max_depth': [2, 5, 10, 20]}\n","grid_model = model_build(veriseti, XGBClassifier(), altveriseti='data', make_gridsearch_opt=True, folds_for_cv=5, param_grid=params_for_grid)\n","print(\"GridSearchCV ile bulunan optimum hiperparametrelerle cross validation: \")\n","the_model=model_build(veriseti, XGBClassifier(**grid_model.best_params_), altveriseti='data', make_crossval=True, folds_for_cv=5)"],"metadata":{"id":"cWfsmCm8vAs1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#RandomForestClassifier için Hyperparameter Tuning\n","\n","#RandomizedSearch Opt.\n","params_for_random = {'bootstrap': [True, False], 'max_depth': [10, 20, 30, 40, 50, 60, 70], 'max_features': ['auto', 'sqrt'], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [200, 400, 600, 800, 1000, 1200]}\n","random_model = model_build(veriseti, RandomForestClassifier(), altveriseti='data', make_randomized_opt=True, folds_for_cv=5, param_grid=params_for_random)\n","print(\"RandomizedSearchCV ile bulunan optimum hiperparametrelerle cross validation: \")\n","the_model=model_build(veriseti, RandomForestClassifier(**random_model.best_params_), altveriseti='data', make_crossval=True, folds_for_cv=5)\n","\n","#Genetik Opt.\n","params_for_genetic = {'n_estimators': Integer(200, 500), 'max_features': Categorical(['auto', 'sqrt', 'log2']), 'max_depth' : Integer(4, 8), 'criterion' :Categorical(['gini', 'entropy'])}\n","genetic_model = model_build(veriseti, RandomForestClassifier(), altveriseti='data', make_genetic_opt=True, folds_for_cv=2, param_grid=params_for_genetic)\n","print(\"GASearchCV ile bulunan optimum hiperparametrelerle cross validation: \")\n","the_model=model_build(veriseti, RandomForestClassifier(**genetic_model.best_params_), altveriseti='data', make_crossval=True, folds_for_cv=5)\n","\n","#GridSearch Opt.\n","params_for_grid = {'n_estimators': [200, 500], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth' : [4,5,6,7,8], 'criterion' :['gini', 'entropy']}\n","grid_model = model_build(veriseti, RandomForestClassifier(), altveriseti='data', make_gridsearch_opt=True, folds_for_cv=2, param_grid=params_for_grid)\n","print(\"GridSearchCV ile bulunan optimum hiperparametrelerle cross validation: \")\n","the_model=model_build(veriseti, RandomForestClassifier(**grid_model.best_params_), altveriseti='data', make_crossval=True, folds_for_cv=5)"],"metadata":{"id":"npJlzPoHdngN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Prediction:**"],"metadata":{"id":"HTjGJP5D9oWO"}},{"cell_type":"code","execution_count":37,"metadata":{"id":"nN0c7M7eWV0Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718209425402,"user_tz":-180,"elapsed":1073,"user":{"displayName":"Fatih Sinan Esen","userId":"08302724942116971542"}},"outputId":"46879fc6-0f32-4250-b9e0-00ce84aad814"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["#Verilen input dosyasını, seçilen verisetini ve seçilen modeli kullanarak sonuç dosyasını hazırla\n","veriseti = \"haberler\"\n","input_dosyasi_adi = \"test_data_\" + veriseti + \".xlsx\"\n","model_adi = \"XGBClassifier\"\n","rapor = sonuc_hazirla(veriseti, input_dosyasi_adi, model_adi) #bu fonksiyon, model_adi yerine eğitilmiş modelin kendisini de parametre olarak kabul eder (Ör: model=model_collection['MultinomialNB']). model_adi veririlirse modeli dosyadan bulur.\n","rapor.to_excel(\"output_\" + veriseti + \".xlsx\")"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"collapsed_sections":["DbX8vOy_o1oA","pg3w27aN9NMP","p-iwZ-Cy9e33","HjUvPkQX9wX3","eTc2zH5hsOhm","HTjGJP5D9oWO","aYiZesKctjhB"],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"vscode":{"interpreter":{"hash":"205293a0de1e1b06c5ae21f4452f215139e8952a65ca957ed55a3298de75cc23"}}},"nbformat":4,"nbformat_minor":0}